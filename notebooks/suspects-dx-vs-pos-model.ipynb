{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from truthnet import truthnet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.stats.api as sms\n",
    "from tqdm.notebook import tqdm\n",
    "import tikzplotlib as tpl\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML\n",
    "import glob\n",
    "from zedstat import zedstat\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    PrecisionRecallDisplay,\n",
    "    RocCurveDisplay,\n",
    "    auc,\n",
    "    mean_squared_error,\n",
    "    precision_recall_curve,\n",
    "    r2_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quasinet.qsampling import qsample\n",
    "from scipy.stats import entropy\n",
    "import random\n",
    "from quasinet.utils import sample_from_dict\n",
    "\n",
    "\n",
    "def _get_qnet(df):\n",
    "    from quasinet import qnet\n",
    "\n",
    "    qn = qnet.Qnet(\n",
    "        feature_names=df.columns.values,\n",
    "        min_samples_split=2,\n",
    "        alpha=0.05,\n",
    "        max_depth=-1,\n",
    "        max_feats=-1,\n",
    "        early_stopping=False,\n",
    "        verbose=0,\n",
    "        random_state=None,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    qn.fit(df.to_numpy(dtype=\"<U21\"))\n",
    "\n",
    "    return qn\n",
    "\n",
    "\n",
    "def _get_tnets(\n",
    "    df,\n",
    "    df_pos=None,\n",
    "    df_neg=None,\n",
    "    diss_file=None,\n",
    "    suspects=None,\n",
    "):\n",
    "    if df_pos is not None and df_neg is not None:\n",
    "        non_null_cols = (\n",
    "            (df.isna().sum() < len(df))\n",
    "            & (df_pos.isna().sum() < len(df_pos))\n",
    "            & (df_neg.isna().sum() < len(df_neg))\n",
    "        )\n",
    "\n",
    "        df_fmtd = df.loc[:, non_null_cols].fillna(-9).astype(int).replace(-9, \"\")\n",
    "        df_pos_fmtd = (\n",
    "            df_pos.loc[:, non_null_cols].fillna(-9).astype(int).replace(-9, \"\")\n",
    "        )\n",
    "        df_neg_fmtd = (\n",
    "            df_neg.loc[:, non_null_cols].fillna(-9).astype(int).replace(-9, \"\")\n",
    "        )\n",
    "        df_fmtd.to_csv(\"df_tmp.csv\", index=False)\n",
    "        df_pos_fmtd.to_csv(\"df_pos_tmp.csv\", index=False)\n",
    "        df_neg_fmtd.to_csv(\"df_neg_tmp.csv\", index=False)\n",
    "\n",
    "        if suspects is not None:\n",
    "            Tr = truthnet()\n",
    "            Tr_pos = truthnet()\n",
    "            features, samples = Tr.load_data(datapath=\"df_tmp.csv\")\n",
    "            features_pos, samples_pos = Tr_pos.load_data(datapath=\"df_pos_tmp.csv\")\n",
    "            Tr.fit(modelpath=\"tmp_Qnet.joblib\")\n",
    "            Tr_pos.fit(modelpath=\"tmp_Qnet_pos.joblib\")\n",
    "            if diss_file is not None:\n",
    "                Tr.dissonance = pd.read_csv(diss_file)\n",
    "            else:\n",
    "                Tr.getDissonance(outfile=\"data/tmp_dissonance_matrix.csv\")\n",
    "                Tr_pos.getDissonance(outfile=\"data/tmp_dissonance_matrix_pos.csv\")\n",
    "            for alpha in [0.01, 0.05, 0.1]:\n",
    "                Tr.getSuspects(alpha=alpha).to_csv(f\"{suspects}_full_model_{alpha}.csv\")\n",
    "                Tr_pos.getSuspects(alpha=alpha).to_csv(\n",
    "                    f\"{suspects}_pos_model_{alpha}.csv\"\n",
    "                )\n",
    "\n",
    "        Tr = _get_qnet(df_fmtd)\n",
    "        Tr_pos = _get_qnet(df_pos_fmtd)\n",
    "        Tr_neg = _get_qnet(df_neg_fmtd)\n",
    "    else:\n",
    "        Tr = truthnet()\n",
    "        length = sum(df.isna().sum() < len(df))\n",
    "        df.fillna(-9).astype(int).replace(-9, \"\").to_csv(\"tmpfile.csv\", index=False)\n",
    "        features, samples = Tr.load_data(datapath=\"tmpfile.csv\")\n",
    "        Tr.fit(modelpath=\"tmp_Qnet.joblib\")\n",
    "        if diss_file is not None:\n",
    "            Tr.dissonance = pd.read_csv(diss_file)\n",
    "        else:\n",
    "            Tr.getDissonance(outfile=\"data/tmp_dissonance_matrix.csv\")\n",
    "        if suspects is not None:\n",
    "            for alpha in [0.01, 0.05, 0.1]:\n",
    "                Tr.getSuspects(alpha=alpha).to_csv(f\"{suspects}_{alpha}.csv\")\n",
    "        coresamples = Tr.getCoresamples(alpha=0.01, steps=length)\n",
    "        if len(coresamples) == len(df):\n",
    "            mean_dissonance = pd.DataFrame(\n",
    "                data=Tr.dissonance.mean(axis=1), columns=[\"mean_dissonance\"]\n",
    "            )\n",
    "            coresamples = mean_dissonance.query(\n",
    "                \"mean_dissonance < mean_dissonance.quantile(0.99)\"\n",
    "            )\n",
    "        df_pos = df.loc[coresamples.index.values]\n",
    "        df_neg = df.loc[~df.index.isin(coresamples.index.values)]\n",
    "\n",
    "        non_null_cols = (\n",
    "            (df.isna().sum() < len(df))\n",
    "            & (df_pos.isna().sum() < len(df_pos))\n",
    "            & (df_neg.isna().sum() < len(df_neg))\n",
    "        )\n",
    "\n",
    "        Tr = _get_qnet(df.loc[:, non_null_cols].fillna(-9).astype(int).replace(-9, \"\"))\n",
    "        Tr_neg = _get_qnet(\n",
    "            df_neg.loc[:, non_null_cols].fillna(-9).astype(int).replace(-9, \"\")\n",
    "        )\n",
    "        Tr_pos = _get_qnet(\n",
    "            df_pos.loc[:, non_null_cols].fillna(-9).astype(int).replace(-9, \"\")\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"all\": Tr,\n",
    "        \"pos\": Tr_pos,\n",
    "        \"neg\": Tr_neg,\n",
    "        \"data\": df.loc[:, non_null_cols].fillna(-9).astype(int).replace(-9, \"\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def _diss_linear(s, qnet, missing_value=0):\n",
    "    diss = list()\n",
    "    Ds = qnet.predict_distributions(s)\n",
    "\n",
    "    for i in range(len(s)):\n",
    "        if s[i] != \"\":\n",
    "            if s[i] in Ds[i].keys():\n",
    "                diss.append(1 - Ds[i][s[i]] / np.max(list(Ds[i].values())))\n",
    "            elif s[i] == \"missing\":\n",
    "                diss.append(missing_value)\n",
    "            else:\n",
    "                diss.append(1)\n",
    "\n",
    "    return np.array(diss)\n",
    "\n",
    "\n",
    "def _diss_log(s, qnet, missing_value=0):\n",
    "    diss = list()\n",
    "    Ds = qnet.predict_distributions(s)\n",
    "\n",
    "    for i in range(len(s)):\n",
    "        if s[i] != \"\":\n",
    "            if s[i] in Ds[i].keys():\n",
    "                diss.append(-np.log(Ds[i][s[i]]))\n",
    "            elif s[i] == \"missing\":\n",
    "                diss.append(missing_value)\n",
    "            else:\n",
    "                diss.append(np.inf)\n",
    "        # else:\n",
    "        # diss.append(missing_value)\n",
    "\n",
    "    return np.array(diss)\n",
    "\n",
    "\n",
    "def _actual_sample_dissonance(\n",
    "    data_sample, diss_models, diss_fcn, order, length, missing_value=0\n",
    "):\n",
    "    if order is None:\n",
    "        order = range(length)\n",
    "\n",
    "    sample = np.full(length, \"\", dtype=\"<U21\")\n",
    "\n",
    "    diss = [list() for model in diss_models]\n",
    "\n",
    "    # print(data_sample)\n",
    "\n",
    "    for i in order:\n",
    "        if data_sample[i] == \"\":\n",
    "            sample[i] = \"missing\"\n",
    "        else:\n",
    "            sample[i] = data_sample[i]\n",
    "        # [print(diss_fcn(sample, model)) for d, model in zip(diss, diss_models)]\n",
    "        for d, model in zip(diss, diss_models):\n",
    "            d.append(diss_fcn(sample, model, missing_value))\n",
    "        # [d.append(diss_fcn(sample, model)) for d, model in zip(diss, diss_models)]\n",
    "\n",
    "    return sample, diss\n",
    "\n",
    "\n",
    "def _all_actual_samples_dissonance(\n",
    "    data_samples, diss_models, diss_fcn, order, length, missing_value=0\n",
    "):\n",
    "    samples = list()\n",
    "    dissonances = list()\n",
    "\n",
    "    for data_sample in tqdm(data_samples):\n",
    "        samp, diss = _actual_sample_dissonance(\n",
    "            data_sample, diss_models, diss_fcn, order, length, missing_value\n",
    "        )\n",
    "        # print(len(diss), len(diss[0]), len(diss[0][8]), diss[0][8])\n",
    "        # print(len(diss), len(diss[0]), len(diss[0][4]), diss[0][4])\n",
    "        samples.append(samp)\n",
    "        dissonances.append(diss)\n",
    "\n",
    "    return samples, dissonances\n",
    "\n",
    "\n",
    "def _sample_with_dissonance(\n",
    "    sample_model,\n",
    "    length,\n",
    "    diss_models,\n",
    "    diss_fcn=_diss_linear,\n",
    "    order=None,\n",
    "    data_samples=None,\n",
    "):\n",
    "    if order is None:\n",
    "        order = range(length)\n",
    "\n",
    "    if data_samples is not None:\n",
    "        data_samples_df = pd.DataFrame(data_samples)\n",
    "        data_sample_values = pd.Series(\n",
    "            {\n",
    "                col: [x for x in data_samples_df[col].unique() if x != \"\"]\n",
    "                for col in data_samples_df\n",
    "            }\n",
    "        )\n",
    "\n",
    "    sample = np.full(length, \"\")\n",
    "\n",
    "    diss = [list() for model in diss_models]\n",
    "\n",
    "    for i in order:\n",
    "        if sample_model is not None:\n",
    "            prob_dict = sample_model.predict_distribution(sample, i)\n",
    "            sample[i] = sample_from_dict(prob_dict)\n",
    "        else:\n",
    "            sample[i] = random.choice(data_sample_values[i])\n",
    "        [d.append(diss_fcn(sample, model)) for d, model in zip(diss, diss_models)]\n",
    "\n",
    "    return sample, diss\n",
    "\n",
    "\n",
    "def _nsamples_with_dissonance(\n",
    "    n_samples,\n",
    "    sample_model,\n",
    "    length,\n",
    "    diss_models,\n",
    "    diss_fcn=_diss_linear,\n",
    "    order=None,\n",
    "    data_samples=None,\n",
    "):\n",
    "    samples = list()\n",
    "    dissonances = list()\n",
    "\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        samp, diss = _sample_with_dissonance(\n",
    "            sample_model,\n",
    "            length,\n",
    "            diss_models,\n",
    "            diss_fcn,\n",
    "            order,\n",
    "            data_samples,\n",
    "        )\n",
    "        samples.append(samp)\n",
    "        dissonances.append(diss)\n",
    "\n",
    "    return samples, dissonances\n",
    "\n",
    "\n",
    "def _dissonance_data_at_question(dissonances, questions_asked):\n",
    "    return np.array(\n",
    "        [np.hstack([d[questions_asked - 1] for d in diss]) for diss in dissonances]\n",
    "    )\n",
    "\n",
    "\n",
    "# generate samples under the given models and compute dissonances under specified diss_models\n",
    "def _sampling_scenario(\n",
    "    n_qsamples,\n",
    "    qsample_model,\n",
    "    n_m2_samples,\n",
    "    m2_model,\n",
    "    diss_models,\n",
    "    length,\n",
    "    n_runif_samples=None,\n",
    "    diss_fcn=_diss_linear,\n",
    "    order=None,\n",
    "    data_samples=None,\n",
    "    missing_value=0,\n",
    "):\n",
    "    samples = {}\n",
    "    dissonances = {}\n",
    "\n",
    "    if order == \"entropy\":\n",
    "        Ds = qsample_model.predict_distributions(np.full(length, \"\"))\n",
    "        entrpy = list()\n",
    "        for i in range(len(Ds)):\n",
    "            entrpy.append(entropy(np.fromiter(Ds[i].values(), dtype=float)))\n",
    "        order = pd.Series(entrpy).sort_values().index\n",
    "\n",
    "    if order == \"random\":\n",
    "        order = list(range(length))\n",
    "        random.shuffle(order)\n",
    "\n",
    "    if data_samples is not None:\n",
    "        samples[\"actual\"], dissonances[\"actual\"] = _all_actual_samples_dissonance(\n",
    "            data_samples.to_numpy(), diss_models, diss_fcn, order, length, missing_value\n",
    "        )\n",
    "\n",
    "    samples[\"qsampled\"], dissonances[\"qsampled\"] = _nsamples_with_dissonance(\n",
    "        n_qsamples, qsample_model, length, diss_models, diss_fcn, order\n",
    "    )\n",
    "\n",
    "    samples[\"m2\"], dissonances[\"m2\"] = _nsamples_with_dissonance(\n",
    "        n_m2_samples, m2_model, length, diss_models, diss_fcn, order\n",
    "    )\n",
    "\n",
    "    if n_runif_samples is not None:\n",
    "        samples[\"runif\"], dissonances[\"runif\"] = _nsamples_with_dissonance(\n",
    "            n_runif_samples,\n",
    "            None,\n",
    "            length,\n",
    "            diss_models,\n",
    "            diss_fcn,\n",
    "            order,\n",
    "            data_samples,\n",
    "        )\n",
    "\n",
    "    return samples, dissonances\n",
    "\n",
    "\n",
    "def _diss_dataset(dissonances, questions_asked, groups=[\"qsampled\", \"m2\"]):\n",
    "    diss_dataset = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                _dissonance_data_at_question(dissonances[group], questions_asked)\n",
    "            ).assign(y=group)\n",
    "            for group in groups\n",
    "        ]\n",
    "    )\n",
    "    return diss_dataset\n",
    "\n",
    "\n",
    "def _save_sampling_scenarios(\n",
    "    iter,\n",
    "    name,\n",
    "    df,\n",
    "    n_qsamples,\n",
    "    n_m2_samples,\n",
    "    df_pos=None,\n",
    "    df_neg=None,\n",
    "    diss_file=None,\n",
    "    diss_fcn=_diss_linear,\n",
    "    order=None,\n",
    "    n_runif_samples=None,\n",
    "    invert_pos=False,\n",
    "    missing_value=0,\n",
    "):\n",
    "    for i in tqdm(iter):\n",
    "        tn = _get_tnets(\n",
    "            df=df,\n",
    "            df_pos=df_pos,\n",
    "            df_neg=df_neg,\n",
    "            diss_file=diss_file,\n",
    "            suspects=f\"{name}_{order}_order_suspects_{i}_\",\n",
    "        )\n",
    "\n",
    "        data_samples = tn[\"data\"]\n",
    "        full_model = tn[\"all\"]\n",
    "        if invert_pos is True:\n",
    "            pos_model = tn[\"neg\"]\n",
    "            neg_model = tn[\"pos\"]\n",
    "        else:\n",
    "            pos_model = tn[\"pos\"]\n",
    "            neg_model = tn[\"neg\"]\n",
    "\n",
    "        length = len(full_model.feature_names)\n",
    "\n",
    "        diss_models = [full_model, neg_model, pos_model]\n",
    "\n",
    "        s, d = _sampling_scenario(\n",
    "            n_qsamples,\n",
    "            full_model,\n",
    "            n_m2_samples,\n",
    "            pos_model,\n",
    "            diss_models,\n",
    "            length,\n",
    "            n_runif_samples,\n",
    "            diss_fcn,\n",
    "            order,\n",
    "            data_samples=data_samples,\n",
    "            missing_value=missing_value,\n",
    "        )\n",
    "\n",
    "        pd.to_pickle(s, f\"{name}_{order}_order_samples_{i}.pkl\")\n",
    "        pd.to_pickle(d, f\"{name}_{order}_order_disson_{i}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ptsd/PTSD_cognet_test_processed.csv\")\n",
    "df_pos = pd.read_csv(\"data/ptsd/PTSD_cognet_test_processed_pos_only.csv\")\n",
    "df_neg = pd.read_csv(\"data/ptsd/PTSD_cognet_test_processed_neg_only.csv\")\n",
    "\n",
    "[\n",
    "    _get_tnets(\n",
    "        df=df,\n",
    "        df_pos=df_pos,\n",
    "        df_neg=df_neg,\n",
    "        diss_file=None,\n",
    "        suspects=f\"pstd_suspects_dx_{datetime.now()}\",\n",
    "    )\n",
    "    for i in tqdm(range(10))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16:52:11.916375',\n",
       " '19:08:04.014408',\n",
       " '17:14:40.156313',\n",
       " '17:36:45.335135',\n",
       " '17:59:09.378503',\n",
       " '18:21:55.947332',\n",
       " '18:44:59.039389',\n",
       " '16:29:07.774240',\n",
       " '19:30:39.248756',\n",
       " '19:51:44.614126']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = list(\n",
    "    set(\n",
    "        [s[53:68] for s in glob.glob(\"suspects-dx-vs-pos-model/pstd_suspects_dx_*.csv\")]\n",
    "    )\n",
    ")\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64),\n",
       " array([], dtype=int64)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = list(\n",
    "    set(\n",
    "        [s[53:68] for s in glob.glob(\"suspects-dx-vs-pos-model/pstd_suspects_dx_*.csv\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "for alpha in [0.01, 0.05, 0.1]:\n",
    "    dfs = []\n",
    "    i = 0\n",
    "    for t in times:\n",
    "        for model in [\"pos_model\", \"full_model\"]:\n",
    "            dfs.append(\n",
    "                pd.read_csv(\n",
    "                    f\"suspects-dx-vs-pos-model/pstd_suspects_dx_2023-09-27 {t}_{model}_{alpha}.csv\"\n",
    "                )\n",
    "                .assign(model=model, run=i)\n",
    "                .set_axis(\n",
    "                    [\"subject\", \"mean_dissonance\", \"model\", \"run\"], axis=\"columns\"\n",
    "                )\n",
    "            )\n",
    "        i = i + 1\n",
    "\n",
    "    dfs = pd.concat(dfs)\n",
    "    dfsu = dfs.groupby([\"run\", \"model\"])[\"subject\"].unique()\n",
    "\n",
    "    display(\n",
    "        [np.intersect1d(dfsu[i][\"full_model\"], dfsu[i][\"pos_model\"]) for i in range(10)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnp_cr = _get_tnets(\n",
    "    df=df,\n",
    "    df_pos=None,\n",
    "    df_neg=None,\n",
    "    diss_file=None,\n",
    "    suspects=f\"tmp_pstd_suspects_core_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14238f81656d45c383bc6da592551d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/1236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b73b799000f4ae09240f7647fc134f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/1236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae18507a8dc49a8925fb49ff386ae3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/1236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/gibbons_global/gibbons_global.csv\")\n",
    "\n",
    "tng = _get_tnets(\n",
    "    df=df,\n",
    "    diss_file=\"mpi_tmp/global_dissonance1.csv\",\n",
    "    suspects=f\"tmp_global_suspects_{datetime.now()}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tng[\"all\"].feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tng[\"pos\"].feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>4590</th>\n",
       "      <th>4591</th>\n",
       "      <th>4592</th>\n",
       "      <th>4593</th>\n",
       "      <th>4594</th>\n",
       "      <th>4596</th>\n",
       "      <th>4631</th>\n",
       "      <th>4632</th>\n",
       "      <th>4634</th>\n",
       "      <th>4635</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1236 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     2  3   5  6 7   8  9 10 11 12  ... 4590 4591 4592 4593 4594 4596 4631   \n",
       "0                                   ...                                     \\\n",
       "1                    1              ...                                      \n",
       "2                                   ...    3                        3        \n",
       "3              1           1        ...                             3        \n",
       "4           1  1                    ...    1                        1        \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1231           2                    ...    3                        5        \n",
       "1232        1           1           ...    2                        3        \n",
       "1233                          1     ...    1                        4        \n",
       "1234        2           2           ...                             2        \n",
       "1235                 1     1        ...    1                        1        \n",
       "\n",
       "     4632 4634 4635  \n",
       "0                    \n",
       "1                    \n",
       "2                    \n",
       "3                    \n",
       "4                    \n",
       "...   ...  ...  ...  \n",
       "1231                 \n",
       "1232                 \n",
       "1233                 \n",
       "1234         2       \n",
       "1235         1       \n",
       "\n",
       "[1236 rows x 362 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tng[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_input_size',\n",
       " '_check_is_fitted',\n",
       " '_combine_distributions',\n",
       " '_map_col_to_non_leaf_nodes',\n",
       " '_parallel_fit_tree',\n",
       " '_predict_distributions_numba',\n",
       " '_predict_proba',\n",
       " 'alpha',\n",
       " 'clear_attributes',\n",
       " 'early_stopping',\n",
       " 'estimators_',\n",
       " 'feature_names',\n",
       " 'fit',\n",
       " 'max_depth',\n",
       " 'max_feats',\n",
       " 'min_samples_split',\n",
       " 'mix',\n",
       " 'mixed',\n",
       " 'n_jobs',\n",
       " 'predict_distribution',\n",
       " 'predict_distributions',\n",
       " 'random_state',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tng[\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pkgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

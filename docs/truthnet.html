<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>truthnet.truthnet API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#666666;background-color:black;//mix-blend-mode:difference;color:#bbbbbb;z-index:3}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#66bb66;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#66FF66}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:transparent;padding:1px 4px;color:#FFA500;overflow-wrap:break-word}h1 code{background:transparent}pre{overflow-wrap:break-word;background:#111111;word-wrap:break-word;border:0;border-top:1px solid #666;border-bottom:1px solid #666;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#333333;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#aaeeaa;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;color:#bbbbbb;background-color:black;overflow-wrap:break-word}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>truthnet.truthnet</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from quasinet.qnet import load_qnet, save_qnet
from quasinet.qnet import qdistance
from quasinet.qsampling import qsample
from quasinet.qnet import membership_degree
import pandas as pd
import numpy as np
from tqdm import tqdm
from quasinet.qnet import Qnet
import dill as pickle 
import gzip
import shap
from scipy.stats import t, lognorm
from .truthfinder import reveal, funcm, funcw, dissonance_distr_median
from distfit import distfit
from sklearn import metrics
from zedstat import zedstat
from concurrent.futures import ProcessPoolExecutor
 
global_NSTR = None
global_steps = None
global_model = None

def init_globals(model, steps, NSTR):
    &#39;&#39;&#39;
    global variable initialization necessary for 
    getting maximum paralleization in calibration

    Parameters:
    model: The model to be used globally across parallel tasks.
    steps: The number of steps to be used for a specific operation, globally.
    NSTR: Network String Representation, a global variable to represent the network state.
    &#39;&#39;&#39;
    global global_model, global_steps,  global_NSTR
    global_model = model
    global_steps = steps
    global_NSTR = NSTR

def task(seed):
    &#39;&#39;&#39;
    Helper function for parallelization

    Parameters:
    seed: An integer seed for random number generation to ensure reproducibility.

    Returns:
    A tuple containing the function &#39;m&#39; output and the median dissonance distribution for a sample.
    &#39;&#39;&#39;
    s=qsample(global_NSTR, global_model, steps=global_steps)
    return funcm(s,global_model),dissonance_distr_median(s,global_model)

class truthnet:
    &#34;&#34;&#34;
    The truthnet class is designed to train the Veritas model which is used to determine if a
    subject is being deceptive or untruthful or insincere in a structured interview. 
    Examples of target scenarios include identifying
    adversarial responses in contexts like mental health diagnosis interviews 
    or automated computer-aided diagnostic tests.
    
    Attributes:
        - datapath (str): Path to the survey or interview database with logged responses.
        - target_label (str): Name of the column in the dataset that identifies the ground truth.
        - index_present (bool): Specifies if the first column in the dataset is an index column.
        - target_label_positive (int): Value indicating a positive case for the target condition.
        - target_label_negative (int): Value indicating a negative case for the target condition.
        - training_fraction (float): Fraction of data used as training data to learn the Q-net models.
        - query_limit (int): Number of features used to determine malingering status in deployment.
        - shap_index (list): Ordered list of indices based on SHAP values for feature importance.
        - problem (str): A description or identifier for the type of problem being addressed.
        - threshold_alpha (float): Significance level for lower decision threshold.
        - threshold_alpha_veritas (float): Significance level for Veritas threshold.
        - veritas_model (dict): model, see detailed documentation on veritas model.
        - problem (str): descriptive string for problem
        - VERBOSE (bool): flag to denote if there should be verbose output
    &#34;&#34;&#34;
    def __init__(self, datapath,
                 target_label,
                 problem=&#39;&#39;,
                 index_present=True,
                 target_label_positive=1,
                 target_label_negative=0,
                 training_fraction=0.3,
                 threshold_alpha=0.1,
                 threshold_alpha_veritas=1-0.015,
                 query_limit=None,
                 VERBOSE=False,
                 shap_index=None):
        self.datapath = datapath
        self.target_label = target_label
        self.index_present = index_present
        self.target_label_positive = target_label_positive
        self.target_label_negative = target_label_negative
        self.training_fraction = training_fraction
        self.query_limit = query_limit
        if query_limit is None:
            self.query_limit = -1
        self.shap_index = shap_index
        self.data = None  # Placeholder for the data once loaded
        self.veritas_model={}
        self.data = None
        self.problem = problem
        self.training_index = None
        self.threshold_alpha = threshold_alpha
        self.threshold_alpha_veritas = threshold_alpha_veritas
        self.VERBOSE = VERBOSE
        
    def fit(self,
            alpha=0.1,
            shap_index=None,
            shapnum=10,
            nullsteps=100000,
            veritas_version=&#39;0.0.1&#39;):
        &#34;&#34;&#34;
        Fits the Veritas model to the provided data. It involves training Q-net models
        for both positive and negative cases and determining feature importance using SHAP values.

        Parameters:
            - alpha (float): The significance level for Qnet.
            - shap_index (list): Predefined list of SHAP indices if available.
            - shapnum (int): Number of samples to calculate SHAP values for.
            - nullsteps (int): Number of steps for q-sampling in the background distribution.
            - veritas_version (str): Version identifier for the model.
        &#34;&#34;&#34;
        
        if self.index_present:
            self.data = pd.read_csv(self.datapath,index_col=0, dtype=str, na_filter=False).fillna(&#39;&#39;).astype(str)
        else:
            self.data = pd.read_csv(self.datapath, dtype=str, na_filter=False).fillna(&#39;&#39;).astype(str)

        if self.VERBOSE:
            print(&#39;data reading complete&#39;)
            
        self.data = self.synccols(self.data)
        
        if self.VERBOSE:
            print(self.data)
        
        num_training=np.rint(self.training_fraction*self.data.index.size).astype(int)
        training_index=np.random.choice(self.data.index.values,num_training, replace=False)

        self.training_index=training_index
        df_training=self.data.loc[training_index,:]
        df_training = self.synccols(df_training)
        df_test = self.data.loc[[x for x in self.data.index.values
                                 if x not in training_index],:][df_training.columns]

        if self.target_label:
        
            df_training_pos=df_training[df_training[self.target_label]==str(self.target_label_positive)]
            df_training_neg=df_training[df_training[self.target_label]==str(self.target_label_negative)]
            Xpos_training=df_training_pos.drop(self.target_label,
                                               axis=1)\
                                         .values.astype(str)
            Xneg_training=df_training_neg.drop(self.target_label,
                                               axis=1)\
                                         .values.astype(str)

            featurenames = df_training_pos.drop(self.target_label,
                                                axis=1).columns

            if self.VERBOSE:
                print(&#34;training qnets&#34;)
            
            modelneg=Qnet(feature_names=featurenames,alpha=alpha)
            modelneg.fit(Xneg_training)
            modelpos=Qnet(feature_names=featurenames,alpha=alpha)
            modelpos.fit(Xpos_training)
            modelneg.training_index=training_index
            modelpos.training_index=training_index
            
        else:
            featurenames = df_training.columns
            X_training=df_training.values.astype(str)

            model=Qnet(feature_names=featurenames,alpha=alpha)
            model.fit(X_training)
            model.training_index=training_index

        
        def funcw_(S):
            return np.array([membership_degree(s,modelneg)
                             /membership_degree(s,modelpos) for s in S])

        def funcm_(S):
            return funcm(S,model)

        if self.target_label:
            X=df_test.drop(self.target_label,
                           axis=1).values.astype(str)
        
            NULLSTR=np.array([&#39;&#39;]*len(modelneg.feature_names))
            s_background=qsample(NULLSTR,modelneg,steps=nullsteps)
            explainer = shap.KernelExplainer(funcw_,np.array([s_background]))
            shap_values = explainer.shap_values(X[:shapnum])
            
            self.shap_index=pd.DataFrame(shap_values.mean(axis=0),
                                         columns=[&#39;shap&#39;])\
                              .sort_values(&#39;shap&#39;,
                                           ascending=False).index.values
            
            modelneg.shap_index=self.shap_index
            modelpos.shap_index=self.shap_index

            # save veritas model
            self.veritas_model[&#39;version&#39;]=veritas_version
            self.veritas_model[&#39;model&#39;]=modelpos
            self.veritas_model[&#39;model_neg&#39;]=modelneg
            self.veritas_model[&#39;problem&#39;]=self.problem
            self.veritas_model[&#39;shapvalues&#39;]=shap_values

        else: 

            X=df_test.values.astype(str)
        
            NULLSTR=np.array([&#39;&#39;]*len(model.feature_names))
            s_background=qsample(NULLSTR,model,steps=nullsteps)
            explainer = shap.KernelExplainer(funcm_,np.array([s_background]))
            shap_values = explainer.shap_values(X[:shapnum])
            
            self.shap_index=pd.DataFrame(shap_values.mean(axis=0),
                                         columns=[&#39;shap&#39;])\
                              .sort_values(&#39;shap&#39;,
                                           ascending=False).index.values
            
            model.shap_index=self.shap_index

            self.veritas_model[&#39;version&#39;]=veritas_version
            self.veritas_model[&#39;model&#39;]=model
            self.veritas_model[&#39;problem&#39;]=self.problem
        
        return

    def save(self, filepath):
        &#39;&#39;&#39;
        save veritas model

        Parameters:
        filepath (str): The path where the model should be saved.
        &#39;&#39;&#39;
        with gzip.open(filepath, &#39;wb&#39;) as file:
            M=self.veritas_model
            pickle.dump(M, file)
    
    def calibrate(self,
                  qsteps=1000,num_workers=11,
                  calibration_num=10000):
        &#34;&#34;&#34;
        Calibrates the decision thresholds for the Veritas model using the distribution of scores
        from the trained model. It involves sampling, revealing, and fitting distributions 
        to determine appropriate thresholds.


        Parameters:
        qsteps (int): Steps for q-sampling during calibration.
        num_workers (int): Number of parallel workers for calibration.
        calibration_num (int): Number of calibration samples.
        &#34;&#34;&#34;

        featurenames = self.veritas_model[&#39;model&#39;].feature_names
        NSTR = np.array([&#39;&#39;] * len(featurenames)).astype(&#39;U100&#39;)
        model = self.veritas_model[&#39;model&#39;]

        if self.VERBOSE:
            print(&#39;calibrating...&#39;)

        seed=0
        init_globals(model, qsteps, NSTR)
        with ProcessPoolExecutor(max_workers=num_workers,
                                 initializer=init_globals,
                                 initargs=(model, qsteps, NSTR)) as executor:
            seeds = [seed for _ in range(calibration_num)]
            results = list(tqdm(executor.map(task, seeds),
                            total=calibration_num))


        lower_ = np.array([x[0] for x in results])
        veritas_ = np.array([x[1] for x in results])
        
        self.veritas_model[&#39;calibration_lower&#39;]=lower_
        self.veritas_model[&#39;calibration_veritas&#39;]=veritas_

        # Fitting distributions to lower and veritas thresholds
        dfit = distfit(distr=&#39;lognorm&#39;,verbose=None)
        dfit.fit_transform(lower_)
        df, loc, scale = dfit.model[&#39;params&#39;]
        dist = lognorm(df, loc=loc, scale=scale)
        self.veritas_model[&#39;dist_lower&#39;] = dist        
        self.veritas_model[&#39;LOWER_THRESHOLD&#39;] = dist.ppf(self.threshold_alpha)

        dfitv = distfit(smooth=10, distr=&#39;lognorm&#39;,verbose=None)
        dfitv.fit_transform(veritas_)
        dfv, locv, scalev = dfitv.model[&#39;params&#39;]
        distv = lognorm(dfv, loc=locv, scale=scalev)
        self.veritas_model[&#39;dist_veritas&#39;] = distv        
        self.veritas_model[&#39;VERITAS_THRESHOLD&#39;] = distv.ppf(self.threshold_alpha_veritas)

        if self.VERBOSE:
            print(self.veritas_model)
        
        # Using test data to infer the decision threshold for the upper threshold
        if self.target_label:
            df_test = self.data.loc[[x for x in self.data.index.values if x not in self.training_index], :]
            featurenames = df_test.drop(self.target_label, axis=1, errors=&#39;ignore&#39;).columns
            labels = df_test[self.target_label].values.astype(int)

            df_test = df_test.drop(self.target_label, axis=1, errors=&#39;ignore&#39;)
            df_test = pd.concat([pd.DataFrame(columns=featurenames),
                                  df_test[featurenames[self.shap_index[:self.query_limit]]]]).fillna(&#39;&#39;)
            X= df_test.values.astype(str)

            pred = np.array([funcw(s,
                         self.veritas_model[&#39;model&#39;],
                         self.veritas_model[&#39;model_neg&#39;]) for s in X])

            # Calculating metrics and determining the upper threshold
            fpr, tpr, thresholds = metrics.roc_curve(labels, pred, pos_label=1)
            rf = pd.DataFrame(tpr, fpr, columns=[&#39;tpr&#39;]).assign(threshold=thresholds)
            rf.index.name = &#39;fpr&#39;
            rf=rf.reset_index()
            zt = zedstat.processRoc(df=rf, order=3, total_samples=2*calibration_num,
                                    positive_samples=calibration_num, alpha=0.01, prevalence=0.5)
            zt.smooth(STEP=0.001)
            zt.allmeasures(interpolate=True)
            zt.usample(precision=3)
            Z = zt.get()
            
            if self.VERBOSE:
                rf.to_csv(&#39;tmp.csv&#39;)
                print(X,labels,pred,rf,Z)
                
            self.veritas_model[&#39;upper_scoretoprobability&#39;] = zt.scoretoprobability
            
            if Z.ppv.values[0] &gt; 0.85:
                THR=0.85
            else:
                THR=Z.ppv.values[2]
                
            self.veritas_model[&#39;UPPER_THRESHOLD&#39;] = Z[Z.ppv &gt; THR].threshold.values[-1]
            self.veritas_model[&#39;AUC&#39;] = zt.auc()
        return 
    
    def synccols(self, df_):
        &#34;&#34;&#34;
        Synchronize columns between positive and negative cases.

        Parameters:
        df_ (DataFrame): The DataFrame to process.

        Returns:
        DataFrame: A DataFrame with synchronized columns.
        &#34;&#34;&#34;
        df=df_.copy()
        if self.target_label:
            df1 = df[df[self.target_label] ==  str(self.target_label_positive)]
            df0 = df[df[self.target_label] ==  str(self.target_label_negative)]
            col1 = df1.replace(&#39;&#39;, pd.NA).dropna(axis=1, how=&#39;all&#39;).columns
            col0 = df0.replace(&#39;&#39;, pd.NA).dropna(axis=1, how=&#39;all&#39;).columns
            col = [x for x in col0 if x in col1]
            return df[col]
        else:
            return remove_identical_columns(df_)    
        
def load_veritas_model(filepath):
    &#39;&#39;&#39;
    Load a Veritas model from a specified file.

    Parameters:
    filepath (str): The path to the file containing the saved Veritas model.

    Returns:
    The loaded Veritas model.
    &#39;&#39;&#39;
    with gzip.open(filepath, &#39;rb&#39;) as file:
        model = pickle.load(file)
    return model

def remove_identical_columns(df):
    &#39;&#39;&#39;
    Remove columns from a DataFrame that have identical values across all rows.

    Parameters:
    df (DataFrame): The DataFrame to process.

    Returns:
    DataFrame: A DataFrame with identical columns removed.
    &#39;&#39;&#39;
    columns_to_drop = [col for col in df.columns if df[col].nunique() == 1]
    df_cleaned = df.drop(columns=columns_to_drop)
    
    return df_cleaned
 

def train(datapath,modelpath,
          shapnum=10,target_label=None,
          query_limit=20,calibration_num=5000):
    &#39;&#39;&#39;
    Train a Veritas model with specified parameters.

    Parameters:
    datapath (str): Path to the data file.
    modelpath (str): Path to save the trained model.
    shapnum (int): Number of samples for SHAP value calculation.
    target_label (str): Target label column name.
    query_limit (int): Limit on the number of features to use.
    calibration_num (int): Number of samples for calibration.

    &#39;&#39;&#39;
    TR=truthnet(datapath=datapath,
                target_label=target_label,
                query_limit=query_limit,VERBOSE=False)
    TR.fit(shapnum=shapnum)
    rf=TR.calibrate(calibration_num=calibration_num)
    TR.save(modelpath)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="truthnet.truthnet.init_globals"><code class="name flex">
<span>def <span class="ident">init_globals</span></span>(<span>model, steps, NSTR)</span>
</code></dt>
<dd>
<div class="desc"><p>global variable initialization necessary for
getting maximum paralleization in calibration</p>
<p>Parameters:
model: The model to be used globally across parallel tasks.
steps: The number of steps to be used for a specific operation, globally.
NSTR: Network String Representation, a global variable to represent the network state.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_globals(model, steps, NSTR):
    &#39;&#39;&#39;
    global variable initialization necessary for 
    getting maximum paralleization in calibration

    Parameters:
    model: The model to be used globally across parallel tasks.
    steps: The number of steps to be used for a specific operation, globally.
    NSTR: Network String Representation, a global variable to represent the network state.
    &#39;&#39;&#39;
    global global_model, global_steps,  global_NSTR
    global_model = model
    global_steps = steps
    global_NSTR = NSTR</code></pre>
</details>
</dd>
<dt id="truthnet.truthnet.load_veritas_model"><code class="name flex">
<span>def <span class="ident">load_veritas_model</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a Veritas model from a specified file.</p>
<p>Parameters:
filepath (str): The path to the file containing the saved Veritas model.</p>
<p>Returns:
The loaded Veritas model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_veritas_model(filepath):
    &#39;&#39;&#39;
    Load a Veritas model from a specified file.

    Parameters:
    filepath (str): The path to the file containing the saved Veritas model.

    Returns:
    The loaded Veritas model.
    &#39;&#39;&#39;
    with gzip.open(filepath, &#39;rb&#39;) as file:
        model = pickle.load(file)
    return model</code></pre>
</details>
</dd>
<dt id="truthnet.truthnet.remove_identical_columns"><code class="name flex">
<span>def <span class="ident">remove_identical_columns</span></span>(<span>df)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove columns from a DataFrame that have identical values across all rows.</p>
<p>Parameters:
df (DataFrame): The DataFrame to process.</p>
<p>Returns:
DataFrame: A DataFrame with identical columns removed.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_identical_columns(df):
    &#39;&#39;&#39;
    Remove columns from a DataFrame that have identical values across all rows.

    Parameters:
    df (DataFrame): The DataFrame to process.

    Returns:
    DataFrame: A DataFrame with identical columns removed.
    &#39;&#39;&#39;
    columns_to_drop = [col for col in df.columns if df[col].nunique() == 1]
    df_cleaned = df.drop(columns=columns_to_drop)
    
    return df_cleaned</code></pre>
</details>
</dd>
<dt id="truthnet.truthnet.task"><code class="name flex">
<span>def <span class="ident">task</span></span>(<span>seed)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper function for parallelization</p>
<p>Parameters:
seed: An integer seed for random number generation to ensure reproducibility.</p>
<p>Returns:
A tuple containing the function 'm' output and the median dissonance distribution for a sample.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def task(seed):
    &#39;&#39;&#39;
    Helper function for parallelization

    Parameters:
    seed: An integer seed for random number generation to ensure reproducibility.

    Returns:
    A tuple containing the function &#39;m&#39; output and the median dissonance distribution for a sample.
    &#39;&#39;&#39;
    s=qsample(global_NSTR, global_model, steps=global_steps)
    return funcm(s,global_model),dissonance_distr_median(s,global_model)</code></pre>
</details>
</dd>
<dt id="truthnet.truthnet.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>datapath, modelpath, shapnum=10, target_label=None, query_limit=20, calibration_num=5000)</span>
</code></dt>
<dd>
<div class="desc"><p>Train a Veritas model with specified parameters.</p>
<p>Parameters:
datapath (str): Path to the data file.
modelpath (str): Path to save the trained model.
shapnum (int): Number of samples for SHAP value calculation.
target_label (str): Target label column name.
query_limit (int): Limit on the number of features to use.
calibration_num (int): Number of samples for calibration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(datapath,modelpath,
          shapnum=10,target_label=None,
          query_limit=20,calibration_num=5000):
    &#39;&#39;&#39;
    Train a Veritas model with specified parameters.

    Parameters:
    datapath (str): Path to the data file.
    modelpath (str): Path to save the trained model.
    shapnum (int): Number of samples for SHAP value calculation.
    target_label (str): Target label column name.
    query_limit (int): Limit on the number of features to use.
    calibration_num (int): Number of samples for calibration.

    &#39;&#39;&#39;
    TR=truthnet(datapath=datapath,
                target_label=target_label,
                query_limit=query_limit,VERBOSE=False)
    TR.fit(shapnum=shapnum)
    rf=TR.calibrate(calibration_num=calibration_num)
    TR.save(modelpath)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="truthnet.truthnet.truthnet"><code class="flex name class">
<span>class <span class="ident">truthnet</span></span>
<span>(</span><span>datapath, target_label, problem='', index_present=True, target_label_positive=1, target_label_negative=0, training_fraction=0.3, threshold_alpha=0.1, threshold_alpha_veritas=0.985, query_limit=None, VERBOSE=False, shap_index=None)</span>
</code></dt>
<dd>
<div class="desc"><p>The truthnet class is designed to train the Veritas model which is used to determine if a
subject is being deceptive or untruthful or insincere in a structured interview.
Examples of target scenarios include identifying
adversarial responses in contexts like mental health diagnosis interviews
or automated computer-aided diagnostic tests.</p>
<h2 id="attributes">Attributes</h2>
<ul>
<li>datapath (str): Path to the survey or interview database with logged responses.</li>
<li>target_label (str): Name of the column in the dataset that identifies the ground truth.</li>
<li>index_present (bool): Specifies if the first column in the dataset is an index column.</li>
<li>target_label_positive (int): Value indicating a positive case for the target condition.</li>
<li>target_label_negative (int): Value indicating a negative case for the target condition.</li>
<li>training_fraction (float): Fraction of data used as training data to learn the Q-net models.</li>
<li>query_limit (int): Number of features used to determine malingering status in deployment.</li>
<li>shap_index (list): Ordered list of indices based on SHAP values for feature importance.</li>
<li>problem (str): A description or identifier for the type of problem being addressed.</li>
<li>threshold_alpha (float): Significance level for lower decision threshold.</li>
<li>threshold_alpha_veritas (float): Significance level for Veritas threshold.</li>
<li>veritas_model (dict): model, see detailed documentation on veritas model.</li>
<li>problem (str): descriptive string for problem</li>
<li>VERBOSE (bool): flag to denote if there should be verbose output</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class truthnet:
    &#34;&#34;&#34;
    The truthnet class is designed to train the Veritas model which is used to determine if a
    subject is being deceptive or untruthful or insincere in a structured interview. 
    Examples of target scenarios include identifying
    adversarial responses in contexts like mental health diagnosis interviews 
    or automated computer-aided diagnostic tests.
    
    Attributes:
        - datapath (str): Path to the survey or interview database with logged responses.
        - target_label (str): Name of the column in the dataset that identifies the ground truth.
        - index_present (bool): Specifies if the first column in the dataset is an index column.
        - target_label_positive (int): Value indicating a positive case for the target condition.
        - target_label_negative (int): Value indicating a negative case for the target condition.
        - training_fraction (float): Fraction of data used as training data to learn the Q-net models.
        - query_limit (int): Number of features used to determine malingering status in deployment.
        - shap_index (list): Ordered list of indices based on SHAP values for feature importance.
        - problem (str): A description or identifier for the type of problem being addressed.
        - threshold_alpha (float): Significance level for lower decision threshold.
        - threshold_alpha_veritas (float): Significance level for Veritas threshold.
        - veritas_model (dict): model, see detailed documentation on veritas model.
        - problem (str): descriptive string for problem
        - VERBOSE (bool): flag to denote if there should be verbose output
    &#34;&#34;&#34;
    def __init__(self, datapath,
                 target_label,
                 problem=&#39;&#39;,
                 index_present=True,
                 target_label_positive=1,
                 target_label_negative=0,
                 training_fraction=0.3,
                 threshold_alpha=0.1,
                 threshold_alpha_veritas=1-0.015,
                 query_limit=None,
                 VERBOSE=False,
                 shap_index=None):
        self.datapath = datapath
        self.target_label = target_label
        self.index_present = index_present
        self.target_label_positive = target_label_positive
        self.target_label_negative = target_label_negative
        self.training_fraction = training_fraction
        self.query_limit = query_limit
        if query_limit is None:
            self.query_limit = -1
        self.shap_index = shap_index
        self.data = None  # Placeholder for the data once loaded
        self.veritas_model={}
        self.data = None
        self.problem = problem
        self.training_index = None
        self.threshold_alpha = threshold_alpha
        self.threshold_alpha_veritas = threshold_alpha_veritas
        self.VERBOSE = VERBOSE
        
    def fit(self,
            alpha=0.1,
            shap_index=None,
            shapnum=10,
            nullsteps=100000,
            veritas_version=&#39;0.0.1&#39;):
        &#34;&#34;&#34;
        Fits the Veritas model to the provided data. It involves training Q-net models
        for both positive and negative cases and determining feature importance using SHAP values.

        Parameters:
            - alpha (float): The significance level for Qnet.
            - shap_index (list): Predefined list of SHAP indices if available.
            - shapnum (int): Number of samples to calculate SHAP values for.
            - nullsteps (int): Number of steps for q-sampling in the background distribution.
            - veritas_version (str): Version identifier for the model.
        &#34;&#34;&#34;
        
        if self.index_present:
            self.data = pd.read_csv(self.datapath,index_col=0, dtype=str, na_filter=False).fillna(&#39;&#39;).astype(str)
        else:
            self.data = pd.read_csv(self.datapath, dtype=str, na_filter=False).fillna(&#39;&#39;).astype(str)

        if self.VERBOSE:
            print(&#39;data reading complete&#39;)
            
        self.data = self.synccols(self.data)
        
        if self.VERBOSE:
            print(self.data)
        
        num_training=np.rint(self.training_fraction*self.data.index.size).astype(int)
        training_index=np.random.choice(self.data.index.values,num_training, replace=False)

        self.training_index=training_index
        df_training=self.data.loc[training_index,:]
        df_training = self.synccols(df_training)
        df_test = self.data.loc[[x for x in self.data.index.values
                                 if x not in training_index],:][df_training.columns]

        if self.target_label:
        
            df_training_pos=df_training[df_training[self.target_label]==str(self.target_label_positive)]
            df_training_neg=df_training[df_training[self.target_label]==str(self.target_label_negative)]
            Xpos_training=df_training_pos.drop(self.target_label,
                                               axis=1)\
                                         .values.astype(str)
            Xneg_training=df_training_neg.drop(self.target_label,
                                               axis=1)\
                                         .values.astype(str)

            featurenames = df_training_pos.drop(self.target_label,
                                                axis=1).columns

            if self.VERBOSE:
                print(&#34;training qnets&#34;)
            
            modelneg=Qnet(feature_names=featurenames,alpha=alpha)
            modelneg.fit(Xneg_training)
            modelpos=Qnet(feature_names=featurenames,alpha=alpha)
            modelpos.fit(Xpos_training)
            modelneg.training_index=training_index
            modelpos.training_index=training_index
            
        else:
            featurenames = df_training.columns
            X_training=df_training.values.astype(str)

            model=Qnet(feature_names=featurenames,alpha=alpha)
            model.fit(X_training)
            model.training_index=training_index

        
        def funcw_(S):
            return np.array([membership_degree(s,modelneg)
                             /membership_degree(s,modelpos) for s in S])

        def funcm_(S):
            return funcm(S,model)

        if self.target_label:
            X=df_test.drop(self.target_label,
                           axis=1).values.astype(str)
        
            NULLSTR=np.array([&#39;&#39;]*len(modelneg.feature_names))
            s_background=qsample(NULLSTR,modelneg,steps=nullsteps)
            explainer = shap.KernelExplainer(funcw_,np.array([s_background]))
            shap_values = explainer.shap_values(X[:shapnum])
            
            self.shap_index=pd.DataFrame(shap_values.mean(axis=0),
                                         columns=[&#39;shap&#39;])\
                              .sort_values(&#39;shap&#39;,
                                           ascending=False).index.values
            
            modelneg.shap_index=self.shap_index
            modelpos.shap_index=self.shap_index

            # save veritas model
            self.veritas_model[&#39;version&#39;]=veritas_version
            self.veritas_model[&#39;model&#39;]=modelpos
            self.veritas_model[&#39;model_neg&#39;]=modelneg
            self.veritas_model[&#39;problem&#39;]=self.problem
            self.veritas_model[&#39;shapvalues&#39;]=shap_values

        else: 

            X=df_test.values.astype(str)
        
            NULLSTR=np.array([&#39;&#39;]*len(model.feature_names))
            s_background=qsample(NULLSTR,model,steps=nullsteps)
            explainer = shap.KernelExplainer(funcm_,np.array([s_background]))
            shap_values = explainer.shap_values(X[:shapnum])
            
            self.shap_index=pd.DataFrame(shap_values.mean(axis=0),
                                         columns=[&#39;shap&#39;])\
                              .sort_values(&#39;shap&#39;,
                                           ascending=False).index.values
            
            model.shap_index=self.shap_index

            self.veritas_model[&#39;version&#39;]=veritas_version
            self.veritas_model[&#39;model&#39;]=model
            self.veritas_model[&#39;problem&#39;]=self.problem
        
        return

    def save(self, filepath):
        &#39;&#39;&#39;
        save veritas model

        Parameters:
        filepath (str): The path where the model should be saved.
        &#39;&#39;&#39;
        with gzip.open(filepath, &#39;wb&#39;) as file:
            M=self.veritas_model
            pickle.dump(M, file)
    
    def calibrate(self,
                  qsteps=1000,num_workers=11,
                  calibration_num=10000):
        &#34;&#34;&#34;
        Calibrates the decision thresholds for the Veritas model using the distribution of scores
        from the trained model. It involves sampling, revealing, and fitting distributions 
        to determine appropriate thresholds.


        Parameters:
        qsteps (int): Steps for q-sampling during calibration.
        num_workers (int): Number of parallel workers for calibration.
        calibration_num (int): Number of calibration samples.
        &#34;&#34;&#34;

        featurenames = self.veritas_model[&#39;model&#39;].feature_names
        NSTR = np.array([&#39;&#39;] * len(featurenames)).astype(&#39;U100&#39;)
        model = self.veritas_model[&#39;model&#39;]

        if self.VERBOSE:
            print(&#39;calibrating...&#39;)

        seed=0
        init_globals(model, qsteps, NSTR)
        with ProcessPoolExecutor(max_workers=num_workers,
                                 initializer=init_globals,
                                 initargs=(model, qsteps, NSTR)) as executor:
            seeds = [seed for _ in range(calibration_num)]
            results = list(tqdm(executor.map(task, seeds),
                            total=calibration_num))


        lower_ = np.array([x[0] for x in results])
        veritas_ = np.array([x[1] for x in results])
        
        self.veritas_model[&#39;calibration_lower&#39;]=lower_
        self.veritas_model[&#39;calibration_veritas&#39;]=veritas_

        # Fitting distributions to lower and veritas thresholds
        dfit = distfit(distr=&#39;lognorm&#39;,verbose=None)
        dfit.fit_transform(lower_)
        df, loc, scale = dfit.model[&#39;params&#39;]
        dist = lognorm(df, loc=loc, scale=scale)
        self.veritas_model[&#39;dist_lower&#39;] = dist        
        self.veritas_model[&#39;LOWER_THRESHOLD&#39;] = dist.ppf(self.threshold_alpha)

        dfitv = distfit(smooth=10, distr=&#39;lognorm&#39;,verbose=None)
        dfitv.fit_transform(veritas_)
        dfv, locv, scalev = dfitv.model[&#39;params&#39;]
        distv = lognorm(dfv, loc=locv, scale=scalev)
        self.veritas_model[&#39;dist_veritas&#39;] = distv        
        self.veritas_model[&#39;VERITAS_THRESHOLD&#39;] = distv.ppf(self.threshold_alpha_veritas)

        if self.VERBOSE:
            print(self.veritas_model)
        
        # Using test data to infer the decision threshold for the upper threshold
        if self.target_label:
            df_test = self.data.loc[[x for x in self.data.index.values if x not in self.training_index], :]
            featurenames = df_test.drop(self.target_label, axis=1, errors=&#39;ignore&#39;).columns
            labels = df_test[self.target_label].values.astype(int)

            df_test = df_test.drop(self.target_label, axis=1, errors=&#39;ignore&#39;)
            df_test = pd.concat([pd.DataFrame(columns=featurenames),
                                  df_test[featurenames[self.shap_index[:self.query_limit]]]]).fillna(&#39;&#39;)
            X= df_test.values.astype(str)

            pred = np.array([funcw(s,
                         self.veritas_model[&#39;model&#39;],
                         self.veritas_model[&#39;model_neg&#39;]) for s in X])

            # Calculating metrics and determining the upper threshold
            fpr, tpr, thresholds = metrics.roc_curve(labels, pred, pos_label=1)
            rf = pd.DataFrame(tpr, fpr, columns=[&#39;tpr&#39;]).assign(threshold=thresholds)
            rf.index.name = &#39;fpr&#39;
            rf=rf.reset_index()
            zt = zedstat.processRoc(df=rf, order=3, total_samples=2*calibration_num,
                                    positive_samples=calibration_num, alpha=0.01, prevalence=0.5)
            zt.smooth(STEP=0.001)
            zt.allmeasures(interpolate=True)
            zt.usample(precision=3)
            Z = zt.get()
            
            if self.VERBOSE:
                rf.to_csv(&#39;tmp.csv&#39;)
                print(X,labels,pred,rf,Z)
                
            self.veritas_model[&#39;upper_scoretoprobability&#39;] = zt.scoretoprobability
            
            if Z.ppv.values[0] &gt; 0.85:
                THR=0.85
            else:
                THR=Z.ppv.values[2]
                
            self.veritas_model[&#39;UPPER_THRESHOLD&#39;] = Z[Z.ppv &gt; THR].threshold.values[-1]
            self.veritas_model[&#39;AUC&#39;] = zt.auc()
        return 
    
    def synccols(self, df_):
        &#34;&#34;&#34;
        Synchronize columns between positive and negative cases.

        Parameters:
        df_ (DataFrame): The DataFrame to process.

        Returns:
        DataFrame: A DataFrame with synchronized columns.
        &#34;&#34;&#34;
        df=df_.copy()
        if self.target_label:
            df1 = df[df[self.target_label] ==  str(self.target_label_positive)]
            df0 = df[df[self.target_label] ==  str(self.target_label_negative)]
            col1 = df1.replace(&#39;&#39;, pd.NA).dropna(axis=1, how=&#39;all&#39;).columns
            col0 = df0.replace(&#39;&#39;, pd.NA).dropna(axis=1, how=&#39;all&#39;).columns
            col = [x for x in col0 if x in col1]
            return df[col]
        else:
            return remove_identical_columns(df_)    </code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="truthnet.truthnet.truthnet.calibrate"><code class="name flex">
<span>def <span class="ident">calibrate</span></span>(<span>self, qsteps=1000, num_workers=11, calibration_num=10000)</span>
</code></dt>
<dd>
<div class="desc"><p>Calibrates the decision thresholds for the Veritas model using the distribution of scores
from the trained model. It involves sampling, revealing, and fitting distributions
to determine appropriate thresholds.</p>
<p>Parameters:
qsteps (int): Steps for q-sampling during calibration.
num_workers (int): Number of parallel workers for calibration.
calibration_num (int): Number of calibration samples.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calibrate(self,
              qsteps=1000,num_workers=11,
              calibration_num=10000):
    &#34;&#34;&#34;
    Calibrates the decision thresholds for the Veritas model using the distribution of scores
    from the trained model. It involves sampling, revealing, and fitting distributions 
    to determine appropriate thresholds.


    Parameters:
    qsteps (int): Steps for q-sampling during calibration.
    num_workers (int): Number of parallel workers for calibration.
    calibration_num (int): Number of calibration samples.
    &#34;&#34;&#34;

    featurenames = self.veritas_model[&#39;model&#39;].feature_names
    NSTR = np.array([&#39;&#39;] * len(featurenames)).astype(&#39;U100&#39;)
    model = self.veritas_model[&#39;model&#39;]

    if self.VERBOSE:
        print(&#39;calibrating...&#39;)

    seed=0
    init_globals(model, qsteps, NSTR)
    with ProcessPoolExecutor(max_workers=num_workers,
                             initializer=init_globals,
                             initargs=(model, qsteps, NSTR)) as executor:
        seeds = [seed for _ in range(calibration_num)]
        results = list(tqdm(executor.map(task, seeds),
                        total=calibration_num))


    lower_ = np.array([x[0] for x in results])
    veritas_ = np.array([x[1] for x in results])
    
    self.veritas_model[&#39;calibration_lower&#39;]=lower_
    self.veritas_model[&#39;calibration_veritas&#39;]=veritas_

    # Fitting distributions to lower and veritas thresholds
    dfit = distfit(distr=&#39;lognorm&#39;,verbose=None)
    dfit.fit_transform(lower_)
    df, loc, scale = dfit.model[&#39;params&#39;]
    dist = lognorm(df, loc=loc, scale=scale)
    self.veritas_model[&#39;dist_lower&#39;] = dist        
    self.veritas_model[&#39;LOWER_THRESHOLD&#39;] = dist.ppf(self.threshold_alpha)

    dfitv = distfit(smooth=10, distr=&#39;lognorm&#39;,verbose=None)
    dfitv.fit_transform(veritas_)
    dfv, locv, scalev = dfitv.model[&#39;params&#39;]
    distv = lognorm(dfv, loc=locv, scale=scalev)
    self.veritas_model[&#39;dist_veritas&#39;] = distv        
    self.veritas_model[&#39;VERITAS_THRESHOLD&#39;] = distv.ppf(self.threshold_alpha_veritas)

    if self.VERBOSE:
        print(self.veritas_model)
    
    # Using test data to infer the decision threshold for the upper threshold
    if self.target_label:
        df_test = self.data.loc[[x for x in self.data.index.values if x not in self.training_index], :]
        featurenames = df_test.drop(self.target_label, axis=1, errors=&#39;ignore&#39;).columns
        labels = df_test[self.target_label].values.astype(int)

        df_test = df_test.drop(self.target_label, axis=1, errors=&#39;ignore&#39;)
        df_test = pd.concat([pd.DataFrame(columns=featurenames),
                              df_test[featurenames[self.shap_index[:self.query_limit]]]]).fillna(&#39;&#39;)
        X= df_test.values.astype(str)

        pred = np.array([funcw(s,
                     self.veritas_model[&#39;model&#39;],
                     self.veritas_model[&#39;model_neg&#39;]) for s in X])

        # Calculating metrics and determining the upper threshold
        fpr, tpr, thresholds = metrics.roc_curve(labels, pred, pos_label=1)
        rf = pd.DataFrame(tpr, fpr, columns=[&#39;tpr&#39;]).assign(threshold=thresholds)
        rf.index.name = &#39;fpr&#39;
        rf=rf.reset_index()
        zt = zedstat.processRoc(df=rf, order=3, total_samples=2*calibration_num,
                                positive_samples=calibration_num, alpha=0.01, prevalence=0.5)
        zt.smooth(STEP=0.001)
        zt.allmeasures(interpolate=True)
        zt.usample(precision=3)
        Z = zt.get()
        
        if self.VERBOSE:
            rf.to_csv(&#39;tmp.csv&#39;)
            print(X,labels,pred,rf,Z)
            
        self.veritas_model[&#39;upper_scoretoprobability&#39;] = zt.scoretoprobability
        
        if Z.ppv.values[0] &gt; 0.85:
            THR=0.85
        else:
            THR=Z.ppv.values[2]
            
        self.veritas_model[&#39;UPPER_THRESHOLD&#39;] = Z[Z.ppv &gt; THR].threshold.values[-1]
        self.veritas_model[&#39;AUC&#39;] = zt.auc()
    return </code></pre>
</details>
</dd>
<dt id="truthnet.truthnet.truthnet.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, alpha=0.1, shap_index=None, shapnum=10, nullsteps=100000, veritas_version='0.0.1')</span>
</code></dt>
<dd>
<div class="desc"><p>Fits the Veritas model to the provided data. It involves training Q-net models
for both positive and negative cases and determining feature importance using SHAP values.</p>
<h2 id="parameters">Parameters</h2>
<ul>
<li>alpha (float): The significance level for Qnet.</li>
<li>shap_index (list): Predefined list of SHAP indices if available.</li>
<li>shapnum (int): Number of samples to calculate SHAP values for.</li>
<li>nullsteps (int): Number of steps for q-sampling in the background distribution.</li>
<li>veritas_version (str): Version identifier for the model.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self,
        alpha=0.1,
        shap_index=None,
        shapnum=10,
        nullsteps=100000,
        veritas_version=&#39;0.0.1&#39;):
    &#34;&#34;&#34;
    Fits the Veritas model to the provided data. It involves training Q-net models
    for both positive and negative cases and determining feature importance using SHAP values.

    Parameters:
        - alpha (float): The significance level for Qnet.
        - shap_index (list): Predefined list of SHAP indices if available.
        - shapnum (int): Number of samples to calculate SHAP values for.
        - nullsteps (int): Number of steps for q-sampling in the background distribution.
        - veritas_version (str): Version identifier for the model.
    &#34;&#34;&#34;
    
    if self.index_present:
        self.data = pd.read_csv(self.datapath,index_col=0, dtype=str, na_filter=False).fillna(&#39;&#39;).astype(str)
    else:
        self.data = pd.read_csv(self.datapath, dtype=str, na_filter=False).fillna(&#39;&#39;).astype(str)

    if self.VERBOSE:
        print(&#39;data reading complete&#39;)
        
    self.data = self.synccols(self.data)
    
    if self.VERBOSE:
        print(self.data)
    
    num_training=np.rint(self.training_fraction*self.data.index.size).astype(int)
    training_index=np.random.choice(self.data.index.values,num_training, replace=False)

    self.training_index=training_index
    df_training=self.data.loc[training_index,:]
    df_training = self.synccols(df_training)
    df_test = self.data.loc[[x for x in self.data.index.values
                             if x not in training_index],:][df_training.columns]

    if self.target_label:
    
        df_training_pos=df_training[df_training[self.target_label]==str(self.target_label_positive)]
        df_training_neg=df_training[df_training[self.target_label]==str(self.target_label_negative)]
        Xpos_training=df_training_pos.drop(self.target_label,
                                           axis=1)\
                                     .values.astype(str)
        Xneg_training=df_training_neg.drop(self.target_label,
                                           axis=1)\
                                     .values.astype(str)

        featurenames = df_training_pos.drop(self.target_label,
                                            axis=1).columns

        if self.VERBOSE:
            print(&#34;training qnets&#34;)
        
        modelneg=Qnet(feature_names=featurenames,alpha=alpha)
        modelneg.fit(Xneg_training)
        modelpos=Qnet(feature_names=featurenames,alpha=alpha)
        modelpos.fit(Xpos_training)
        modelneg.training_index=training_index
        modelpos.training_index=training_index
        
    else:
        featurenames = df_training.columns
        X_training=df_training.values.astype(str)

        model=Qnet(feature_names=featurenames,alpha=alpha)
        model.fit(X_training)
        model.training_index=training_index

    
    def funcw_(S):
        return np.array([membership_degree(s,modelneg)
                         /membership_degree(s,modelpos) for s in S])

    def funcm_(S):
        return funcm(S,model)

    if self.target_label:
        X=df_test.drop(self.target_label,
                       axis=1).values.astype(str)
    
        NULLSTR=np.array([&#39;&#39;]*len(modelneg.feature_names))
        s_background=qsample(NULLSTR,modelneg,steps=nullsteps)
        explainer = shap.KernelExplainer(funcw_,np.array([s_background]))
        shap_values = explainer.shap_values(X[:shapnum])
        
        self.shap_index=pd.DataFrame(shap_values.mean(axis=0),
                                     columns=[&#39;shap&#39;])\
                          .sort_values(&#39;shap&#39;,
                                       ascending=False).index.values
        
        modelneg.shap_index=self.shap_index
        modelpos.shap_index=self.shap_index

        # save veritas model
        self.veritas_model[&#39;version&#39;]=veritas_version
        self.veritas_model[&#39;model&#39;]=modelpos
        self.veritas_model[&#39;model_neg&#39;]=modelneg
        self.veritas_model[&#39;problem&#39;]=self.problem
        self.veritas_model[&#39;shapvalues&#39;]=shap_values

    else: 

        X=df_test.values.astype(str)
    
        NULLSTR=np.array([&#39;&#39;]*len(model.feature_names))
        s_background=qsample(NULLSTR,model,steps=nullsteps)
        explainer = shap.KernelExplainer(funcm_,np.array([s_background]))
        shap_values = explainer.shap_values(X[:shapnum])
        
        self.shap_index=pd.DataFrame(shap_values.mean(axis=0),
                                     columns=[&#39;shap&#39;])\
                          .sort_values(&#39;shap&#39;,
                                       ascending=False).index.values
        
        model.shap_index=self.shap_index

        self.veritas_model[&#39;version&#39;]=veritas_version
        self.veritas_model[&#39;model&#39;]=model
        self.veritas_model[&#39;problem&#39;]=self.problem
    
    return</code></pre>
</details>
</dd>
<dt id="truthnet.truthnet.truthnet.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filepath)</span>
</code></dt>
<dd>
<div class="desc"><p>save veritas model</p>
<p>Parameters:
filepath (str): The path where the model should be saved.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, filepath):
    &#39;&#39;&#39;
    save veritas model

    Parameters:
    filepath (str): The path where the model should be saved.
    &#39;&#39;&#39;
    with gzip.open(filepath, &#39;wb&#39;) as file:
        M=self.veritas_model
        pickle.dump(M, file)</code></pre>
</details>
</dd>
<dt id="truthnet.truthnet.truthnet.synccols"><code class="name flex">
<span>def <span class="ident">synccols</span></span>(<span>self, df_)</span>
</code></dt>
<dd>
<div class="desc"><p>Synchronize columns between positive and negative cases.</p>
<p>Parameters:
df_ (DataFrame): The DataFrame to process.</p>
<p>Returns:
DataFrame: A DataFrame with synchronized columns.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def synccols(self, df_):
    &#34;&#34;&#34;
    Synchronize columns between positive and negative cases.

    Parameters:
    df_ (DataFrame): The DataFrame to process.

    Returns:
    DataFrame: A DataFrame with synchronized columns.
    &#34;&#34;&#34;
    df=df_.copy()
    if self.target_label:
        df1 = df[df[self.target_label] ==  str(self.target_label_positive)]
        df0 = df[df[self.target_label] ==  str(self.target_label_negative)]
        col1 = df1.replace(&#39;&#39;, pd.NA).dropna(axis=1, how=&#39;all&#39;).columns
        col0 = df0.replace(&#39;&#39;, pd.NA).dropna(axis=1, how=&#39;all&#39;).columns
        col = [x for x in col0 if x in col1]
        return df[col]
    else:
        return remove_identical_columns(df_)    </code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<img src="logozed_nowhite.png" alt="drawing" style="width:400px;"/>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="truthnet" href="index.html">truthnet</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="truthnet.truthnet.init_globals" href="#truthnet.truthnet.init_globals">init_globals</a></code></li>
<li><code><a title="truthnet.truthnet.load_veritas_model" href="#truthnet.truthnet.load_veritas_model">load_veritas_model</a></code></li>
<li><code><a title="truthnet.truthnet.remove_identical_columns" href="#truthnet.truthnet.remove_identical_columns">remove_identical_columns</a></code></li>
<li><code><a title="truthnet.truthnet.task" href="#truthnet.truthnet.task">task</a></code></li>
<li><code><a title="truthnet.truthnet.train" href="#truthnet.truthnet.train">train</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="truthnet.truthnet.truthnet" href="#truthnet.truthnet.truthnet">truthnet</a></code></h4>
<ul class="">
<li><code><a title="truthnet.truthnet.truthnet.calibrate" href="#truthnet.truthnet.truthnet.calibrate">calibrate</a></code></li>
<li><code><a title="truthnet.truthnet.truthnet.fit" href="#truthnet.truthnet.truthnet.fit">fit</a></code></li>
<li><code><a title="truthnet.truthnet.truthnet.save" href="#truthnet.truthnet.truthnet.save">save</a></code></li>
<li><code><a title="truthnet.truthnet.truthnet.synccols" href="#truthnet.truthnet.truthnet.synccols">synccols</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
Author: <a href="https://zed.uchicago.edu"> Zero Knowledge Discovery, University of Chicago</a>. Email: ishanu@uchicago.edu
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>